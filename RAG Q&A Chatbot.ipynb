{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installs\n",
    "Restart after installing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "! pip install -qq -U langchain-huggingface\n",
    "! pip install -qq -U langchain-community\n",
    "! pip install -qq -U langchain\n",
    "! pip install -qq -U rouge_score\n",
    "! pip install -qq -U bitsandbytes\n",
    "! pip install -qq -U accelerate\n",
    "! pip install -qq -U faiss-gpu\n",
    "! pip install -qq -U peft\n",
    "! pip install -qq -U torch\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T07:20:20.712820Z",
     "iopub.status.busy": "2024-11-01T07:20:20.712533Z",
     "iopub.status.idle": "2024-11-01T07:20:35.795027Z",
     "shell.execute_reply": "2024-11-01T07:20:35.794054Z",
     "shell.execute_reply.started": "2024-11-01T07:20:20.712788Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.36 s, sys: 1.52 s, total: 10.9 s\n",
      "Wall time: 15.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import textwrap\n",
    "import time\n",
    "import pandas as pd\n",
    "from datasets import Dataset, load_metric\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "import langchain\n",
    "\n",
    "### loaders\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "\n",
    "### splits\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "### prompts\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "### vector stores\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "### models\n",
    "from langchain_huggingface import HuggingFacePipeline, HuggingFaceEmbeddings\n",
    "\n",
    "### retrievers\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForCausalLM, AutoModelForSeq2SeqLM,\n",
    "    BitsAndBytesConfig, pipeline, GenerationConfig,\n",
    "    Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq\n",
    ")\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T07:32:27.970917Z",
     "iopub.status.busy": "2024-11-01T07:32:27.970199Z",
     "iopub.status.idle": "2024-11-01T07:32:27.976351Z",
     "shell.execute_reply": "2024-11-01T07:32:27.975370Z",
     "shell.execute_reply.started": "2024-11-01T07:32:27.970877Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    # LLMs\n",
    "    # With bigger LLM like wizardlm or llama2-7b-chat fine-tuning can be skipped, while with Flan-T5, a smaller and easier to fine-tune model, fine-tuning is recommended.\n",
    "    model_name = 'google/flan-t5-base' # TheBloke/wizardLM-7B-HF, llama2-7b-chat, mistral-7B, google/flan-t5-base\n",
    "    fine_tune_with_LoRA = True\n",
    "    \n",
    "    temperature = 0\n",
    "    top_p = 0.95\n",
    "    repetition_penalty = 1.15\n",
    "\n",
    "    # splitting\n",
    "    split_chunk_size = 400\n",
    "    split_overlap = 0\n",
    "\n",
    "    # similar passages\n",
    "    k = 2\n",
    "    \n",
    "    # Vector Database Embedding\n",
    "    embedding_model = 'sentence-transformers/all-mpnet-base-v2'\n",
    "    \n",
    "    # paths\n",
    "    DOCs_path = '/kaggle/input/questionanswer-dataset/text_data/text_data'\n",
    "    Output_folder = './rag-vectordb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T08:11:27.880115Z",
     "iopub.status.busy": "2024-11-01T08:11:27.879200Z",
     "iopub.status.idle": "2024-11-01T08:11:27.936568Z",
     "shell.execute_reply": "2024-11-01T08:11:27.935663Z",
     "shell.execute_reply.started": "2024-11-01T08:11:27.880066Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleTitle</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>DifficultyFromQuestioner</th>\n",
       "      <th>DifficultyFromAnswerer</th>\n",
       "      <th>ArticleFile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abraham_Lincoln</td>\n",
       "      <td>Was Abraham Lincoln the sixteenth President of...</td>\n",
       "      <td>yes</td>\n",
       "      <td>easy</td>\n",
       "      <td>easy</td>\n",
       "      <td>S08_set3_a4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abraham_Lincoln</td>\n",
       "      <td>Was Abraham Lincoln the sixteenth President of...</td>\n",
       "      <td>Yes.</td>\n",
       "      <td>easy</td>\n",
       "      <td>easy</td>\n",
       "      <td>S08_set3_a4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abraham_Lincoln</td>\n",
       "      <td>Did Lincoln sign the National Banking Act of 1...</td>\n",
       "      <td>yes</td>\n",
       "      <td>easy</td>\n",
       "      <td>medium</td>\n",
       "      <td>S08_set3_a4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abraham_Lincoln</td>\n",
       "      <td>Did Lincoln sign the National Banking Act of 1...</td>\n",
       "      <td>Yes.</td>\n",
       "      <td>easy</td>\n",
       "      <td>easy</td>\n",
       "      <td>S08_set3_a4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abraham_Lincoln</td>\n",
       "      <td>Did his mother die of pneumonia?</td>\n",
       "      <td>no</td>\n",
       "      <td>easy</td>\n",
       "      <td>medium</td>\n",
       "      <td>S08_set3_a4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ArticleTitle                                           Question Answer  \\\n",
       "0  Abraham_Lincoln  Was Abraham Lincoln the sixteenth President of...    yes   \n",
       "1  Abraham_Lincoln  Was Abraham Lincoln the sixteenth President of...   Yes.   \n",
       "2  Abraham_Lincoln  Did Lincoln sign the National Banking Act of 1...    yes   \n",
       "3  Abraham_Lincoln  Did Lincoln sign the National Banking Act of 1...   Yes.   \n",
       "4  Abraham_Lincoln                   Did his mother die of pneumonia?     no   \n",
       "\n",
       "  DifficultyFromQuestioner DifficultyFromAnswerer  ArticleFile  \n",
       "0                     easy                   easy  S08_set3_a4  \n",
       "1                     easy                   easy  S08_set3_a4  \n",
       "2                     easy                 medium  S08_set3_a4  \n",
       "3                     easy                   easy  S08_set3_a4  \n",
       "4                     easy                 medium  S08_set3_a4  "
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_S08 = pd.read_csv('/kaggle/input/questionanswer-dataset/S08_question_answer_pairs.txt', sep='\\t')\n",
    "df_S08.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T08:11:28.515615Z",
     "iopub.status.busy": "2024-11-01T08:11:28.514973Z",
     "iopub.status.idle": "2024-11-01T08:11:28.526291Z",
     "shell.execute_reply": "2024-11-01T08:11:28.525282Z",
     "shell.execute_reply.started": "2024-11-01T08:11:28.515577Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing NULL values: (1715, 6)\n",
      "After removing NULL values: (1150, 6)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Before removing NULL values: {df_S08.shape}\")\n",
    "\n",
    "df_S08 = df_S08.dropna()\n",
    "\n",
    "print(f\"After removing NULL values: {df_S08.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T08:11:28.918950Z",
     "iopub.status.busy": "2024-11-01T08:11:28.918102Z",
     "iopub.status.idle": "2024-11-01T08:11:28.924921Z",
     "shell.execute_reply": "2024-11-01T08:11:28.923916Z",
     "shell.execute_reply.started": "2024-11-01T08:11:28.918914Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing duplicates: (602, 6)\n"
     ]
    }
   ],
   "source": [
    "df_S08 = df_S08.drop_duplicates(subset=['Question'])\n",
    "\n",
    "print(f\"After removing duplicates: {df_S08.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T08:11:29.738578Z",
     "iopub.status.busy": "2024-11-01T08:11:29.738197Z",
     "iopub.status.idle": "2024-11-01T08:11:29.760477Z",
     "shell.execute_reply": "2024-11-01T08:11:29.759423Z",
     "shell.execute_reply.started": "2024-11-01T08:11:29.738536Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_S08['Question'] = df_S08.apply(\n",
    "    lambda x: x['Question'] if all(word in x['Question'] for word in x['ArticleTitle'].replace('_', ' ').split()) \n",
    "    else x['ArticleTitle'].replace('_', ' ') + \". \" + x['Question'], \n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T07:20:50.352444Z",
     "iopub.status.busy": "2024-11-01T07:20:50.351575Z",
     "iopub.status.idle": "2024-11-01T07:20:50.506902Z",
     "shell.execute_reply": "2024-11-01T07:20:50.505978Z",
     "shell.execute_reply.started": "2024-11-01T07:20:50.352407Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 566.26it/s]\n"
     ]
    }
   ],
   "source": [
    "loader = DirectoryLoader(\n",
    "    CFG.DOCs_path,\n",
    "    glob=\"S08*.txt.clean\",\n",
    "    loader_cls=TextLoader,\n",
    "    show_progress=True,\n",
    "    use_multithreading=True,\n",
    "    loader_kwargs={\"encoding\": \"ISO-8859-1\"}\n",
    ")\n",
    "\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T07:20:51.935845Z",
     "iopub.status.busy": "2024-11-01T07:20:51.935473Z",
     "iopub.status.idle": "2024-11-01T07:20:51.940777Z",
     "shell.execute_reply": "2024-11-01T07:20:51.939594Z",
     "shell.execute_reply.started": "2024-11-01T07:20:51.935814Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 40 pages in total\n"
     ]
    }
   ],
   "source": [
    "print(f'We have {len(documents)} pages in total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T07:20:52.783721Z",
     "iopub.status.busy": "2024-11-01T07:20:52.783347Z",
     "iopub.status.idle": "2024-11-01T07:20:52.789109Z",
     "shell.execute_reply": "2024-11-01T07:20:52.788064Z",
     "shell.execute_reply.started": "2024-11-01T07:20:52.783692Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otter\n",
      "\n",
      "\n",
      "\n",
      "Otters are amphibious (or in one case aquatic) carnivorous mammals.  The otter subfamily Lutrinae forms part of the family Mustelidae, which also includes weasels, polecats, badgers, as well as others. With 13 species in 7 genera, otters have an almost worldwide distribution.\n",
      "\n",
      "An otter's den is called a holt.  Male otters are dog-otters, females are bitches and babies are cubs or pups.  The collective noun romp is sometimes used for a group of otters, being descriptive of their often playful nature.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Otters have long, slim bodies and relatively short limbs, with webbed paws. Most h\n"
     ]
    }
   ],
   "source": [
    "print(documents[0].page_content[:600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T07:20:54.670897Z",
     "iopub.status.busy": "2024-11-01T07:20:54.670527Z",
     "iopub.status.idle": "2024-11-01T07:20:54.796906Z",
     "shell.execute_reply": "2024-11-01T07:20:54.796014Z",
     "shell.execute_reply.started": "2024-11-01T07:20:54.670868Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otter Otters are amphibious (or in one case aquatic) carnivorous mammals. The otter subfamily Lutrinae forms part of the family Mustelidae, which also includes weasels, polecats, badgers, as well as others. With 13 species in 7 genera, otters have an almost worldwide distribution. An otter's den is called a holt. Male otters are dog-otters, females are bitches and babies are cubs or pups. The collective noun romp is sometimes used for a group of otters, being descriptive of their often playful nature. Otters have long, slim bodies and relatively short limbs, with webbed paws. Most have sharp c\n"
     ]
    }
   ],
   "source": [
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    # Replace multiple newlines with a single newline\n",
    "    text = re.sub(r'\\n+', '\\n', text)\n",
    "    # Replace multiple spaces with a single space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()  # Optional: Strip leading/trailing whitespace\n",
    "\n",
    "# Clean each document\n",
    "for doc in documents:\n",
    "    doc.page_content = clean_text(doc.page_content)\n",
    "\n",
    "print(documents[0].page_content[:600])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T07:21:18.162543Z",
     "iopub.status.busy": "2024-11-01T07:21:18.161892Z",
     "iopub.status.idle": "2024-11-01T07:21:18.675825Z",
     "shell.execute_reply": "2024-11-01T07:21:18.674915Z",
     "shell.execute_reply.started": "2024-11-01T07:21:18.162511Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have created 3162 chunks from 40 pages\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = CFG.split_chunk_size,\n",
    "    chunk_overlap = CFG.split_overlap\n",
    ")\n",
    "\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f'We have created {len(texts)} chunks from {len(documents)} pages')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T07:21:25.169028Z",
     "iopub.status.busy": "2024-11-01T07:21:25.168170Z",
     "iopub.status.idle": "2024-11-01T07:21:42.945508Z",
     "shell.execute_reply": "2024-11-01T07:21:42.944613Z",
     "shell.execute_reply.started": "2024-11-01T07:21:25.168993Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.3 s, sys: 1.03 s, total: 16.3 s\n",
      "Wall time: 17.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "vectordb = FAISS.from_documents(\n",
    "    texts,\n",
    "    HuggingFaceEmbeddings(model_name=CFG.embedding_model)\n",
    ")\n",
    "\n",
    "### persist vector database\n",
    "vectordb.save_local(f\"{CFG.Output_folder}/faiss_index_rag\")\n",
    "#vectordb = FAISS.load_local(f\"{CFG.Output_folder}/faiss_index_rag\", HuggingFaceEmbeddings(model_name=CFG.embedding_model), allow_dangerous_deserialization=True)\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T08:11:40.679312Z",
     "iopub.status.busy": "2024-11-01T08:11:40.678551Z",
     "iopub.status.idle": "2024-11-01T08:11:51.433207Z",
     "shell.execute_reply": "2024-11-01T08:11:51.432263Z",
     "shell.execute_reply.started": "2024-11-01T08:11:40.679262Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching contexts: 100%|██████████| 602/602 [00:10<00:00, 56.07it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Was Abraham Lincoln the sixteenth President of...</td>\n",
       "      <td>Abraham Lincoln Abraham Lincoln (February 12, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abraham Lincoln. Did Lincoln sign the National...</td>\n",
       "      <td>Transcontinental Railroad, which was completed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abraham Lincoln. Did his mother die of pneumonia?</td>\n",
       "      <td>born. Theodore Roosevelt's mother Mittie died ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Abraham Lincoln. How many long was Lincoln's f...</td>\n",
       "      <td>a frequent visitor to Kentucky, he would have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Abraham Lincoln. When did Lincoln begin his po...</td>\n",
       "      <td>not like killing animals, even for food. Thoug...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0  Was Abraham Lincoln the sixteenth President of...   \n",
       "2  Abraham Lincoln. Did Lincoln sign the National...   \n",
       "4  Abraham Lincoln. Did his mother die of pneumonia?   \n",
       "6  Abraham Lincoln. How many long was Lincoln's f...   \n",
       "8  Abraham Lincoln. When did Lincoln begin his po...   \n",
       "\n",
       "                                             Context  \n",
       "0  Abraham Lincoln Abraham Lincoln (February 12, ...  \n",
       "2  Transcontinental Railroad, which was completed...  \n",
       "4  born. Theodore Roosevelt's mother Mittie died ...  \n",
       "6  a frequent visitor to Kentucky, he would have ...  \n",
       "8  not like killing animals, even for food. Thoug...  "
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": CFG.k, \"search_type\": \"similarity\"})\n",
    "\n",
    "# Initialize an empty list to store contexts\n",
    "contexts = []\n",
    "\n",
    "# Loop through each question and fetch its context\n",
    "for question in tqdm(df_S08['Question'], desc=\"Fetching contexts\"):\n",
    "\n",
    "    results = retriever.invoke(question)\n",
    "    \n",
    "    # Extract page contents from results and join them as a single string\n",
    "    context = \" \".join([doc.page_content for doc in results])\n",
    "    \n",
    "    # Append the context to the list\n",
    "    contexts.append(context)\n",
    "\n",
    "# Add the contexts list as a new column to the dataframe\n",
    "df_S08['Context'] = contexts\n",
    "\n",
    "# Display the dataframe to verify\n",
    "df_S08[['Question', 'Context']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T08:12:03.351076Z",
     "iopub.status.busy": "2024-11-01T08:12:03.350638Z",
     "iopub.status.idle": "2024-11-01T08:12:04.858199Z",
     "shell.execute_reply": "2024-11-01T08:12:04.857228Z",
     "shell.execute_reply.started": "2024-11-01T08:12:03.351041Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.28 s, sys: 298 ms, total: 1.58 s\n",
      "Wall time: 1.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_repo = CFG.model_name\n",
    "        \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_repo)\n",
    "\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "if CFG.fine_tune_with_LoRA:\n",
    "    \n",
    "    def base_model_init():\n",
    "        return AutoModelForSeq2SeqLM.from_pretrained(model_repo, torch_dtype=torch.bfloat16, device_map = 'auto',)\n",
    "    \n",
    "    base_model = base_model_init()\n",
    "    \n",
    "    max_len = base_model.config.n_positions\n",
    "    \n",
    "else:\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.float16,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "    )\n",
    "\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_repo,\n",
    "        device_map = 'auto',\n",
    "        quantization_config = bnb_config,\n",
    "        low_cpu_mem_usage = True,\n",
    "        trust_remote_code = True,\n",
    "    )\n",
    "    max_len = base_model.config.max_position_embeddings\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T08:12:06.451300Z",
     "iopub.status.busy": "2024-11-01T08:12:06.450922Z",
     "iopub.status.idle": "2024-11-01T08:12:06.456218Z",
     "shell.execute_reply": "2024-11-01T08:12:06.455324Z",
     "shell.execute_reply.started": "2024-11-01T08:12:06.451270Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Use only the following pieces of context to answer the question.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template = prompt_template, \n",
    "    input_variables = [\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T08:12:08.131063Z",
     "iopub.status.busy": "2024-11-01T08:12:08.130369Z",
     "iopub.status.idle": "2024-11-01T08:12:08.971953Z",
     "shell.execute_reply": "2024-11-01T08:12:08.971049Z",
     "shell.execute_reply.started": "2024-11-01T08:12:08.131030Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing rows: 100%|██████████| 602/602 [00:00<00:00, 726.40it/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(row):\n",
    "    formatted_prompt = PROMPT.format(question=row['Question'], context=row['Context'])\n",
    "    inputs = tokenizer(formatted_prompt, max_length=max_len, truncation=True)\n",
    "    labels = tokenizer(row[\"Answer\"], max_length=max_len, truncation=True)\n",
    "\n",
    "    return pd.Series({\n",
    "        'input_ids': inputs.input_ids,\n",
    "        'attention_mask': inputs.attention_mask,\n",
    "        'labels': labels.input_ids\n",
    "    })\n",
    "\n",
    "if CFG.fine_tune_with_LoRA:\n",
    "    tqdm.pandas(desc=\"Tokenizing rows\")\n",
    "    df_S08[['input_ids', 'attention_mask', 'labels']] = df_S08.progress_apply(tokenize_function, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T08:12:09.268857Z",
     "iopub.status.busy": "2024-11-01T08:12:09.268024Z",
     "iopub.status.idle": "2024-11-01T08:12:09.307420Z",
     "shell.execute_reply": "2024-11-01T08:12:09.306497Z",
     "shell.execute_reply.started": "2024-11-01T08:12:09.268824Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of the datasets:\n",
      "Training: 481 samples\n",
      "Validation: 121 samples\n"
     ]
    }
   ],
   "source": [
    "hf_dataset = Dataset.from_pandas(df_S08)\n",
    "\n",
    "train_test_split = hf_dataset.train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = train_test_split['train']\n",
    "eval_dataset = train_test_split['test']\n",
    "\n",
    "print(f\"Shapes of the datasets:\")\n",
    "print(f\"Training: {len(train_dataset)} samples\")\n",
    "print(f\"Validation: {len(eval_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform PEFT with LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T08:12:10.148111Z",
     "iopub.status.busy": "2024-11-01T08:12:10.147761Z",
     "iopub.status.idle": "2024-11-01T08:12:11.679087Z",
     "shell.execute_reply": "2024-11-01T08:12:11.678076Z",
     "shell.execute_reply.started": "2024-11-01T08:12:10.148084Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.58 s, sys: 217 ms, total: 1.8 s\n",
      "Wall time: 1.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "peft_model = None\n",
    "\n",
    "if CFG.fine_tune_with_LoRA:\n",
    "    base_model = base_model_init()\n",
    "    \n",
    "    lora_config = LoraConfig(\n",
    "        r=32, # Rank\n",
    "        lora_alpha=32,\n",
    "        target_modules=[\"q\", \"v\"],\n",
    "        lora_dropout=0.05,\n",
    "        bias=\"none\",\n",
    "        task_type=TaskType.SEQ_2_SEQ_LM\n",
    "    )\n",
    "\n",
    "    peft_model = get_peft_model(base_model, lora_config)\n",
    "    \n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T08:12:11.680904Z",
     "iopub.status.busy": "2024-11-01T08:12:11.680607Z",
     "iopub.status.idle": "2024-11-01T08:12:11.760274Z",
     "shell.execute_reply": "2024-11-01T08:12:11.759399Z",
     "shell.execute_reply.started": "2024-11-01T08:12:11.680877Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if CFG.fine_tune_with_LoRA:\n",
    "    output_dir = f'./peft-qa-training-{str(int(time.time()))}'\n",
    "    batch_size = 8\n",
    "\n",
    "    peft_training_args = Seq2SeqTrainingArguments(\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        \n",
    "        num_train_epochs=1,\n",
    "        learning_rate=1e-3,\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        warmup_ratio=0.01,\n",
    "        \n",
    "        evaluation_strategy=\"steps\",\n",
    "        logging_steps=15,\n",
    "        \n",
    "        output_dir=output_dir,\n",
    "        report_to=\"none\"\n",
    "    )\n",
    "    \n",
    "    data_collator = DataCollatorForSeq2Seq(tokenizer)\n",
    "\n",
    "    peft_trainer = Seq2SeqTrainer(\n",
    "        model=peft_model,\n",
    "        args=peft_training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        data_collator=data_collator,\n",
    "        tokenizer=tokenizer\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T08:12:11.765615Z",
     "iopub.status.busy": "2024-11-01T08:12:11.765077Z",
     "iopub.status.idle": "2024-11-01T08:12:42.287299Z",
     "shell.execute_reply": "2024-11-01T08:12:42.286240Z",
     "shell.execute_reply.started": "2024-11-01T08:12:11.765583Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:29, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.840400</td>\n",
       "      <td>1.392334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.588300</td>\n",
       "      <td>1.328857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.699000</td>\n",
       "      <td>1.338013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.797100</td>\n",
       "      <td>1.327759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if CFG.fine_tune_with_LoRA:\n",
    "    peft_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🤗 Pipeline & Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T08:12:46.036188Z",
     "iopub.status.busy": "2024-11-01T08:12:46.035820Z",
     "iopub.status.idle": "2024-11-01T08:12:46.056817Z",
     "shell.execute_reply": "2024-11-01T08:12:46.055960Z",
     "shell.execute_reply.started": "2024-11-01T08:12:46.036157Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "generation_config = GenerationConfig(\n",
    "    max_length=max_len,\n",
    "    temperature=CFG.temperature,\n",
    "    top_p=CFG.top_p,\n",
    "    repetition_penalty=CFG.repetition_penalty,\n",
    ")\n",
    "\n",
    "if CFG.fine_tune_with_LoRA:\n",
    "    peft_model.eval()\n",
    "    task = \"text2text-generation\"\n",
    "\n",
    "else:\n",
    "    base_model.eval()\n",
    "    task=\"text-generation\"\n",
    "    \n",
    "pipe = pipeline(\n",
    "    task=task,\n",
    "    model=peft_model if CFG.fine_tune_with_LoRA else base_model,\n",
    "    tokenizer=tokenizer,\n",
    "    device_map=\"auto\",\n",
    "    truncation=True,\n",
    "    generation_config=generation_config\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline = pipe)\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T08:12:47.396045Z",
     "iopub.status.busy": "2024-11-01T08:12:47.395629Z",
     "iopub.status.idle": "2024-11-01T08:12:47.624178Z",
     "shell.execute_reply": "2024-11-01T08:12:47.623069Z",
     "shell.execute_reply.started": "2024-11-01T08:12:47.396008Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Use only the following pieces of context to answer the question.\n",
      "\n",
      "tail reaches 60 to 110cm. Shoulder height is 45 to 80 cm. Males are considerably larger than females and weigh 37 to 90 kg compared to 28 to 60 kg for females. Ronald M. Nowak: Walker's Mammals of the World. Johns Hopkins University Press, 1999 ISBN 0-8018-5789-9 One of many spotted cats, a leopard may be mistaken for a cheetah or a jaguar. The leopard has rosettes rather than cheetah's simple puá¹á¸Ã¡rÄ«ka (\"tiger\", among other things), then borrowed into Greek. The leopard is an agile and graceful predator. Although smaller than the other members of Panthera, the leopard is still able to take large prey given a massive skull that well utilizes powerful jaw muscles. Its body is comparatively long for a cat and its legs are short. Head and body length is between 90 and 190 cm, the\n",
      "\n",
      "Question: How long is a leopard's tail?\n",
      "Answer: 60 to 110cm\n",
      "\n",
      "Correct Answer: 60 to 110cm\n"
     ]
    }
   ],
   "source": [
    "def check_llm_response(dataset, indx):\n",
    "    query = dataset[indx]['Question']\n",
    "    context = dataset[indx]['Context']\n",
    "\n",
    "    # Format the prompt using the question\n",
    "    formatted_prompt = PROMPT.format(question=query, context=context)\n",
    "\n",
    "    # Use the formatted prompt with the LLM\n",
    "    llm_response = llm.invoke(formatted_prompt)\n",
    "    \n",
    "    if CFG.fine_tune_with_LoRA:\n",
    "        llm_response = formatted_prompt + \" \" + llm_response\n",
    "        \n",
    "    print(llm_response)\n",
    "    print(f\"\\nCorrect Answer: {dataset[indx]['Answer']}\")\n",
    "\n",
    "#check_llm_response(wrong_ans, 0) # use wrong_ans you find later to check better pipeline args\n",
    "check_llm_response(eval_dataset, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retriever chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T08:13:01.477807Z",
     "iopub.status.busy": "2024-11-01T08:13:01.477435Z",
     "iopub.status.idle": "2024-11-01T08:13:01.486595Z",
     "shell.execute_reply": "2024-11-01T08:13:01.485628Z",
     "shell.execute_reply.started": "2024-11-01T08:13:01.477775Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever(search_kwargs = {\"k\": CFG.k, \"search_type\" : \"similarity\"})\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm = llm,\n",
    "    chain_type = \"stuff\", # map_reduce, map_rerank, stuff, refine\n",
    "    retriever = retriever, \n",
    "    chain_type_kwargs = {\"prompt\": PROMPT},\n",
    "    return_source_documents = True,\n",
    "    verbose = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-process outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T08:13:02.950137Z",
     "iopub.status.busy": "2024-11-01T08:13:02.949774Z",
     "iopub.status.idle": "2024-11-01T08:13:02.958065Z",
     "shell.execute_reply": "2024-11-01T08:13:02.957106Z",
     "shell.execute_reply.started": "2024-11-01T08:13:02.950107Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def wrap_text_preserve_newlines(text, width=700):\n",
    "    # Split the input text into lines based on newline characters\n",
    "    lines = text.split('\\n')\n",
    "\n",
    "    # Wrap each line individually\n",
    "    wrapped_lines = [textwrap.fill(line, width=width) for line in lines]\n",
    "\n",
    "    # Join the wrapped lines back together using newline characters\n",
    "    wrapped_text = '\\n'.join(wrapped_lines)\n",
    "\n",
    "    return wrapped_text\n",
    "\n",
    "\n",
    "def process_llm_response(llm_response):\n",
    "    ans = wrap_text_preserve_newlines(llm_response['result'])\n",
    "    \n",
    "    sources_used = ' \\n'.join(\n",
    "        [\n",
    "            source.metadata['source'].split('/')[-1][:-4]\n",
    "            + (' - page: ' + str(source.metadata['page']) if 'page' in source.metadata else '')\n",
    "            + (f'\\nContent: {source.page_content}' if CFG.fine_tune_with_LoRA else '')\n",
    "            for source in llm_response['source_documents']\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    ans = ans + '\\n\\nSources: \\n' + sources_used\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T08:13:03.876566Z",
     "iopub.status.busy": "2024-11-01T08:13:03.876191Z",
     "iopub.status.idle": "2024-11-01T08:13:03.881661Z",
     "shell.execute_reply": "2024-11-01T08:13:03.880737Z",
     "shell.execute_reply.started": "2024-11-01T08:13:03.876535Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def llm_ans(query):\n",
    "    llm_response = qa_chain.invoke(query)\n",
    "    ans = process_llm_response(llm_response)\n",
    "    if CFG.fine_tune_with_LoRA:\n",
    "        ans = f\"Question: {query}\\nLLM Answer: \" + ans\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluations\n",
    "- Check model on a single sample\n",
    "- Calculate average recall score on validation dataset\n",
    "- Check wrong answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T08:13:04.802234Z",
     "iopub.status.busy": "2024-11-01T08:13:04.801873Z",
     "iopub.status.idle": "2024-11-01T08:13:05.101231Z",
     "shell.execute_reply": "2024-11-01T08:13:05.100506Z",
     "shell.execute_reply.started": "2024-11-01T08:13:04.802204Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load the ROUGE metric\n",
    "metric = load_metric(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T08:13:05.815242Z",
     "iopub.status.busy": "2024-11-01T08:13:05.814887Z",
     "iopub.status.idle": "2024-11-01T08:13:06.147341Z",
     "shell.execute_reply": "2024-11-01T08:13:06.146415Z",
     "shell.execute_reply.started": "2024-11-01T08:13:05.815212Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: John Adams. With what party did Adams run for presidency?\n",
      "LLM Answer: Federalist\n",
      "\n",
      "Sources: \n",
      "S08_set3_a1.txt.c\n",
      "Content: Hamilton. Because of Adams's seniority and the need for a northern president, he was elected as the Federalist nominee for president in 1796, over Thomas Jefferson, the leader of the opposition Democratic-Republican Party. His success was due to peace and prosperity; Washington and Hamilton had averted war with Britain by the Jay Treaty of 1795. Ferling (1992) pp 316-32 Adams' two terms as Vice \n",
      "S08_set3_a1.txt.c\n",
      "Content: Quincy rather than actively campaign for the Presidency. He wanted to stay out of what he called the silly and wicked game. His party, however, campaigned for him, while the Republicans campaigned for Jefferson. It was expected that Adams would dominate the votes in New England, while Jefferson was expected to win in the Southern states. In the end, Adams won the election by a narrow margin of 71\n",
      "\n",
      "Correct Answer: The Federalist Party\n",
      "\n",
      "ROUGE Recall Scores: {'rouge1': 0.3333333333333333, 'rouge2': 0.0, 'rougeL': 0.3333333333333333, 'rougeLsum': 0.3333333333333333}\n"
     ]
    }
   ],
   "source": [
    "def extract_prediction(llm_output):\n",
    "    return llm_output.split(\"Answer:\")[1].split(\"Sources:\")[0].strip()\n",
    "\n",
    "def evaluate_answer(dataset, indx):\n",
    "    # Get the question and correct answer from the DataFrame\n",
    "    query = dataset[indx]['Question']\n",
    "    correct_answer = dataset[indx]['Answer']\n",
    "\n",
    "    # Get the predicted answer from the language model\n",
    "    pred_ans = llm_ans(query)\n",
    "\n",
    "    print(pred_ans)\n",
    "    print(f\"\\nCorrect Answer: {correct_answer}\")\n",
    "\n",
    "    # Compute ROUGE scores\n",
    "    rouge_score = metric.compute(\n",
    "        predictions=[extract_prediction(pred_ans)],\n",
    "        references=[correct_answer],\n",
    "        use_stemmer=True\n",
    "    )\n",
    "\n",
    "    # Extract recall scores for different ROUGE metrics\n",
    "    fmeasures = {\n",
    "        'rouge1': rouge_score['rouge1'].mid.recall,\n",
    "        'rouge2': rouge_score['rouge2'].mid.recall,\n",
    "        'rougeL': rouge_score['rougeL'].mid.recall,\n",
    "        'rougeLsum': rouge_score['rougeLsum'].mid.recall\n",
    "    }\n",
    "\n",
    "    print(f\"\\nROUGE Recall Scores: {fmeasures}\")\n",
    "\n",
    "evaluate_answer(eval_dataset, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T08:13:08.676451Z",
     "iopub.status.busy": "2024-11-01T08:13:08.676028Z",
     "iopub.status.idle": "2024-11-01T08:13:56.906104Z",
     "shell.execute_reply": "2024-11-01T08:13:56.905195Z",
     "shell.execute_reply.started": "2024-11-01T08:13:08.676416Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baef33e5ec254ceba79ba8962024fb1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing predictions:   0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define a function to make predictions\n",
    "def predict(batch):\n",
    "    queries = batch['Question']\n",
    "    \n",
    "    # Get the predicted answers from the model for the entire batch\n",
    "    pred_ans = [llm_ans(query) for query in queries]\n",
    "    \n",
    "    # Extract predictions from LLM output\n",
    "    extracted_preds = [extract_prediction(ans) for ans in pred_ans]\n",
    "    \n",
    "    # Initialize lists to store ROUGE scores\n",
    "    recalls = []\n",
    "    \n",
    "    # Calculate ROUGE score for each prediction and store recalls\n",
    "    for pred, ref in zip(extracted_preds, batch['Answer']):\n",
    "        result = metric.compute(predictions=[pred], references=[ref])\n",
    "        recalls.append(result['rouge1'].mid.recall)\n",
    "    \n",
    "    # Return predictions, references, and low recall indices\n",
    "    return {\n",
    "        'prediction': extracted_preds, \n",
    "        'reference': batch['Answer'],\n",
    "        'recalls': recalls\n",
    "    }\n",
    "\n",
    "# Apply the function to all rows in the dataset\n",
    "predicted_dataset = eval_dataset.map(\n",
    "    predict,\n",
    "    batched=True,\n",
    "    batch_size=16,\n",
    "    desc=\"Processing predictions\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T08:13:59.608095Z",
     "iopub.status.busy": "2024-11-01T08:13:59.607408Z",
     "iopub.status.idle": "2024-11-01T08:13:59.882427Z",
     "shell.execute_reply": "2024-11-01T08:13:59.881457Z",
     "shell.execute_reply.started": "2024-11-01T08:13:59.608059Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Recall Scores: {'rouge1': 0.6733852916203682, 'rouge2': 0.20900857515690052, 'rougeL': 0.6699366198633716, 'rougeLsum': 0.6717573666004761}\n"
     ]
    }
   ],
   "source": [
    "# Compute the ROUGE score for the entire dataset\n",
    "rouge_score = metric.compute(\n",
    "    predictions=predicted_dataset['prediction'],\n",
    "    references=predicted_dataset['reference'],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True\n",
    ")\n",
    "\n",
    "# Extract recall scores into a dictionary\n",
    "fmeasures = {key: rouge_score[key].mid.recall for key in ['rouge1', 'rouge2', 'rougeL', 'rougeLsum']}\n",
    "\n",
    "print(f\"ROUGE Recall Scores: {fmeasures}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T08:14:03.684993Z",
     "iopub.status.busy": "2024-11-01T08:14:03.684621Z",
     "iopub.status.idle": "2024-11-01T08:14:03.696074Z",
     "shell.execute_reply": "2024-11-01T08:14:03.695067Z",
     "shell.execute_reply.started": "2024-11-01T08:14:03.684961Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of wrong answers: 41 (34%)\n"
     ]
    }
   ],
   "source": [
    "# Collect the low recall indices based on recalls < 0.5\n",
    "low_recall_indices = [i for i, recall in enumerate(predicted_dataset['recalls']) if recall < 0.5]\n",
    "wrong_ans = eval_dataset.select(low_recall_indices)\n",
    "\n",
    "# Display the filtered dataframe\n",
    "percentage_wrong = round((len(wrong_ans) / len(eval_dataset)) * 100)\n",
    "print(f\"Number of wrong answers: {len(wrong_ans)} ({percentage_wrong}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T08:14:11.445555Z",
     "iopub.status.busy": "2024-11-01T08:14:11.444664Z",
     "iopub.status.idle": "2024-11-01T08:14:11.750760Z",
     "shell.execute_reply": "2024-11-01T08:14:11.749762Z",
     "shell.execute_reply.started": "2024-11-01T08:14:11.445519Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Are otters herbivores?\n",
      "LLM Answer: Yes\n",
      "\n",
      "Sources: \n",
      "S08_set1_a7.txt.c\n",
      "Content: species hunt for 3 to 5 hours a day, and nursing mothers up to 8 hours a day. Most otters have fish as the primary item in their diet, supplemented by frogs, crayfish and crabs. Some are expert at opening shellfish, and others will take any available small mammals or birds. This prey-dependence leaves otters very vulnerable to prey depletion. Otters are very active, chasing prey in the water or \n",
      "S08_set1_a7.txt.c\n",
      "Content: humans hunted them almost to extinction. By the time the 1911 Fur Seal Treaty gave them protection, so few sea otters remained that the fur trade had become unprofitable. Sea otters eat shellfish and other invertebrates (especially clams, abalone, and sea urchins ), frequently using rocks as crude tools to smash open shells. They grow to 1 to 1.5 m (2.5 to 5 feet) in length and weigh 30 kg (about\n",
      "\n",
      "Correct Answer: No\n",
      "\n",
      "ROUGE Recall Scores: {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n"
     ]
    }
   ],
   "source": [
    "evaluate_answer(wrong_ans, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "- Things I found had the most impact on models output quality in my experiments:\n",
    "    - Splitting: chunk size, overlap\n",
    "    - Search: k\n",
    "    - Pipeline parameters (temperature, top_p, penalty)\n",
    "    - Embeddings function\n",
    "    - Question with or without title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 2735,
     "sourceId": 4525,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30498,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
